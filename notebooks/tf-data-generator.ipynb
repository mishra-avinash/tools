{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-29T09:50:35.104250Z",
     "start_time": "2017-10-29T09:50:34.906510Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Containes a helper class for image input pipelines in tensorflow.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.data import Dataset\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework.ops import convert_to_tensor\n",
    "\n",
    "IMAGENET_MEAN = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32)\n",
    "\n",
    "\n",
    "class ImageDataGenerator(object):\n",
    "    \"\"\"Wrapper class around the new Tensorflows dataset pipeline.\n",
    "    Requires Tensorflow >= version 1.12rc0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_paths,labels, mode, batch_size, num_classes, shuffle=True, \n",
    "                 num_threds = 4, buffer_size=1000,input_img_size = [128,128]):\n",
    "        \"\"\"Create a new ImageDataGenerator.\n",
    "        Recieves list of image paths and list of corresponding labels. Using this data,\n",
    "        this class will create TensrFlow datasets, that can be used to train\n",
    "        e.g. a convolutional neural network.\n",
    "        Args:\n",
    "            img_paths: list of image paths,\n",
    "            labels : list of labels for corresponding image index in img_paths\n",
    "            mode: Either 'training' or 'validation'. Depending on this value,\n",
    "                different parsing functions will be used.\n",
    "            batch_size: Number of images per batch.\n",
    "            num_classes: Number of classes in the dataset.\n",
    "            shuffle: Wether or not to shuffle the data in the dataset and the\n",
    "                initial file list.\n",
    "            buffer_size: Number of images used as buffer for TensorFlows\n",
    "                shuffling of the dataset.\n",
    "        Raises:\n",
    "            ValueError: If an invalid mode is passed.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.input_img_size = input_img_size\n",
    "\n",
    "        # number of samples in the dataset\n",
    "        self.data_size = len(self.labels)\n",
    "\n",
    "        # initial shuffling of the file and label lists (together!)\n",
    "        if shuffle:\n",
    "            self._shuffle_lists()\n",
    "\n",
    "        # convert lists to TF tensor\n",
    "        self.img_paths = convert_to_tensor(self.img_paths, dtype=dtypes.string)\n",
    "        self.labels = convert_to_tensor(self.labels, dtype=dtypes.int32)\n",
    "\n",
    "        # create dataset\n",
    "        data = Dataset.from_tensor_slices((self.img_paths, self.labels))\n",
    "\n",
    "        # distinguish between train/infer. when calling the parsing functions\n",
    "        if mode == 'training':\n",
    "            data = data.map(self._parse_function_train, num_threads=num_threds,\n",
    "                      output_buffer_size=100*batch_size)\n",
    "\n",
    "        elif mode == 'inference':\n",
    "            data = data.map(self._parse_function_inference, num_threads=num_threds,\n",
    "                      output_buffer_size=100*batch_size)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode '%s'.\" % (mode))\n",
    "\n",
    "        # shuffle the first `buffer_size` elements of the dataset\n",
    "        if shuffle:\n",
    "            data = data.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "        # create a new dataset with batches of images\n",
    "        data = data.batch(batch_size)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def _shuffle_lists(self):\n",
    "        \"\"\"Conjoined shuffling of the list of paths and labels.\"\"\"\n",
    "        path = self.img_paths\n",
    "        labels = self.labels\n",
    "        permutation = np.random.permutation(self.data_size)\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "        for i in permutation:\n",
    "            self.img_paths.append(path[i])\n",
    "            self.labels.append(labels[i])\n",
    "\n",
    "    def _parse_function_train(self, filename, label):\n",
    "        \"\"\"Input parser for samples of the training set.\"\"\"\n",
    "        # convert label number into one-hot-encoding\n",
    "        one_hot = tf.one_hot(label, self.num_classes)\n",
    "\n",
    "        # load and preprocess the image\n",
    "        img_string = tf.read_file(filename)\n",
    "        img_decoded = tf.image.decode_jpeg(img_string, channels=3)\n",
    "        img_resized = tf.image.resize_images(img_decoded, [128,128])\n",
    "        \"\"\"\n",
    "        Dataaugmentation comes here.\n",
    "        \"\"\"\n",
    "        img_centered = tf.subtract(img_resized, IMAGENET_MEAN)\n",
    "        img_random_flipped = tf.image.random_flip_left_right(img_centered)\n",
    "        \n",
    "\n",
    "        return img_random_flipped, one_hot\n",
    "\n",
    "    def _parse_function_inference(self, filename, label):\n",
    "        \"\"\"Input parser for samples of the validation/test set.\"\"\"\n",
    "        # convert label number into one-hot-encoding\n",
    "        one_hot = tf.one_hot(label, self.num_classes)\n",
    "\n",
    "        # load and preprocess the image\n",
    "        img_string = tf.read_file(filename)\n",
    "        img_decoded = tf.image.decode_png(img_string, channels=3)\n",
    "        img_resized = tf.image.resize_images(img_decoded, [128,128])\n",
    "        img_centered = tf.subtract(img_resized, IMAGENET_MEAN)\n",
    "\n",
    "        return img_centered, one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-29T09:50:36.177285Z",
     "start_time": "2017-10-29T09:50:36.051554Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_paths = ['q','q']\n",
    "train_labels = [1,0]\n",
    "\n",
    "train_data_gen = ImageDataGenerator(img_paths=train_paths,labels=train_labels,mode='training',\n",
    "                                    num_classes=2,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
